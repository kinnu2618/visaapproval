{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "617628e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d05483",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Visadataset_numerical.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7b8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['no of employees'] < 0, 'no of employees'] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13a73461",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no of employees'] = df['no of employees'].fillna(df['no of employees'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0cbdfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('case status', axis=1)\n",
    "y = df['case status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54531983",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1248657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20042, 10)\n",
      "(5011, 10)\n",
      "(20042,)\n",
      "(5011,)\n"
     ]
    }
   ],
   "source": [
    "item = [X_train, X_test, y_train, y_test]\n",
    "for i in item:\n",
    "    print(i.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86406667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "from io import StringIO\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5f02034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'LightGBM': LGBMClassifier(random_state=42),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dff51207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate models\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else np.zeros_like(y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "        'F1-Score': f1_score(y_test, y_pred, zero_division=0),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_prob) if y_prob.sum() > 0 else 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73bb0762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Training Decision Tree...\n",
      "Training Random Forest...\n",
      "Training SVM...\n",
      "Training KNN...\n",
      "Training XGBoost...\n",
      "Training LightGBM...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 6641, number of negative: 13401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 734\n",
      "[LightGBM] [Info] Number of data points in the train set: 20042, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.331354 -> initscore=-0.702067\n",
      "[LightGBM] [Info] Start training from score -0.702067\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate ML models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\")\n",
    "    results[name] = evaluate_model(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34a6e9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance Summary:\n",
      "                     Accuracy  Precision    Recall  F1-Score   ROC-AUC\n",
      "Logistic Regression  0.656156   0.000000  0.000000  0.000000  0.540698\n",
      "Decision Tree        0.655159   0.498530  0.492165  0.495327  0.616368\n",
      "Random Forest        0.725404   0.630158  0.487522  0.549738  0.757486\n",
      "SVM                  0.656156   0.000000  0.000000  0.000000  0.567954\n",
      "KNN                  0.624027   0.424696  0.263494  0.325215  0.542660\n",
      "XGBoost              0.743165   0.667951  0.503192  0.573982  0.774857\n",
      "LightGBM             0.750549   0.678222  0.522345  0.590164  0.785834\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Performance Summary:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca302617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Highest Accuracy Model:\n",
      "Model: LightGBM\n",
      "Accuracy: 0.7505\n"
     ]
    }
   ],
   "source": [
    "# Find the model with the highest accuracy\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy'])\n",
    "best_model = results_df['Accuracy'].idxmax()\n",
    "best_accuracy = results_df['Accuracy'].max()\n",
    "\n",
    "# Output the best model\n",
    "print(\"\\nHighest Accuracy Model:\")\n",
    "print(f\"Model: {best_model}\")\n",
    "print(f\"Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41dff710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d2d2a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = LGBMClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0215eeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 6641, number of negative: 13401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 734\n",
      "[LightGBM] [Info] Number of data points in the train set: 20042, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.331354 -> initscore=-0.702067\n",
      "[LightGBM] [Info] Start training from score -0.702067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0018c9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7505487926561565"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "227397f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(mod,open('mod.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "842c355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('mod.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19f2dc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "prediction = loaded_model.predict(sample)\n",
    "print(\"Prediction:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6da8fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0050461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(best_model,open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0b265d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = pickle.load(open('model.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cae1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [[1,\t0,\t0,\t0,\t98,\t1897,\t4,\t83434.0300,\t3,\t1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc64ade2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 6641, number of negative: 13401\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 734\n",
      "[LightGBM] [Info] Number of data points in the train set: 20042, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.331354 -> initscore=-0.702067\n",
      "[LightGBM] [Info] Start training from score -0.702067\n",
      "Accuracy: 0.7505487926561565\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Train the model\n",
    "mod = LGBMClassifier()\n",
    "mod.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "accuracy = mod.score(X_test, y_test)  # Returns accuracy\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d34de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
